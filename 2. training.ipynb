{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data has been pre-processed and converted into train test sets, the train set can be used for training the model. In this step the algorithm maps the features or the independent variables to the output dependent variable. The module cuML has lot of algorithms for classification problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests is an ensemble algorithm that consists of a group of decision trees. The average predictions of all decision trees is taken as the prediction of the Random Forests algorithm. I will be using random forest classifier from cuML module. The reason for using Random Forest algorithm is because it is the best traditional machine learning algorithm out there. It can even match up the results of neural networks by increasing the number of trees, but the model will overfit then. Usually, data scientists train multiple models and choose the best. I will try multiple algorithms in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import RandomForestClassifier as cuRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyper-parameters will be set and the random forest object will be created. The description of the hyper-parameters and there default values are given below. The default values are selected with a lot of research and experimentations by the developers. So, I will be using the default values for the first experiment and then tune it accordingly for further experiments. \n",
    "* n_estimators: Number of trees in RF, default value is 100. I will go ahead with 100. Increasing this value makes the algorithm more complex and resource hungry. THe accuracy will increase but the model might overfit the data.\n",
    "* max_depth: Max depth of each tree, default is 16. In sklearn the default is unlimited. But our data is huge. Keeping to it unlimited will consume lot of time in training. So, i'll keep it at 16.\n",
    "* n_bins: Number of bins used in split point calculation, default is 128. Most of the features have normal distribution data. So, i will not increase it and keep it at 128.\n",
    "* n_streams: CUDA stream to use for parallel processing on GPU, default is 4. I am using GPU, so this will be fine.\n",
    "* max_samples: Percentage of input data to be considered for each tree, default is 1. Using whole data for each tree might overfit the data but will improve accuracy. I will keep it as 1.\n",
    "* split_criterion: Split algorithm, default is 0 for gini impurity. Gini and entropy can be used for classification. Previous experiments have shown gini to perform better.\n",
    "* random_state: Seed used for Random Number Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cuml Random Forest params\n",
    "cu_rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 16,\n",
    "    'n_bins': 128,\n",
    "    'n_streams': 4,\n",
    "    'max_samples': 1,\n",
    "    'split_criterion': 0,\n",
    "    'random_state': 123\n",
    "}\n",
    "cu_rf = cuRF(**cu_rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will train the Random Forest classifier with the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 288 ms, total: 1min 36s\n",
      "Wall time: 26.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cu_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The the predict method will be run to give predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 50s, sys: 231 ms, total: 3min 51s\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# using the predict method on test set\n",
    "y_pred = cu_rf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use accuracy score function to find out the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7332103252410889\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a bad score. I will do some hyperparameter optimizations in the next section and see if there is any improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try with different hyper-parameters settings to see if better results comes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuml Random Forest params\n",
    "cu_rf_params_2 = {\n",
    "    'n_estimators': 500, # increase no. of trees to 500\n",
    "    'max_depth': 10, # change to 10\n",
    "    'n_bins': 180, # change to 180 as for bigger datasets increasing this value increases accuracy\n",
    "    'n_streams': 4, # CUDA stream to use for parallel processing on GPU, default is 4\n",
    "    'max_samples': 1, # Percentage of input data to be considered for each tree, default is 1\n",
    "    'split_criterion': 0, # Split algorithm, default is 0 for gini impurity\n",
    "    'random_state': 1234 # Seed used for Random Number Generator\n",
    "}\n",
    "cu_rf_2 = cuRF(**cu_rf_params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 15s, sys: 1.06 s, total: 6min 16s\n",
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cu_rf_2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 33s, sys: 564 ms, total: 11min 33s\n",
      "Wall time: 11min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# using the predict method on test set\n",
    "y_pred_2 = cu_rf_2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.71075439453125\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy has reduced with this combination of parameters. Let's try one more combination. I will change max_depth back to default 16 and n_bins as 128. But keep n_estimators as 500 itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 2s, sys: 1.51 s, total: 8min 3s\n",
      "Wall time: 2min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# cuml Random Forest params\n",
    "cu_rf_params_3 = {\n",
    "    'n_estimators': 500, # increase no. of trees to 500\n",
    "    'max_depth': 16, # change to 16\n",
    "    'n_bins': 128, # change to 128\n",
    "    'n_streams': 4, # CUDA stream to use for parallel processing on GPU, default is 4\n",
    "    'max_samples': 1, # Percentage of input data to be considered for each tree, default is 1\n",
    "    'split_criterion': 0, # Split algorithm, default is 0 for gini impurity\n",
    "    'random_state': 12345 # Seed used for Random Number Generator\n",
    "}\n",
    "cu_rf_3 = cuRF(**cu_rf_params_3)\n",
    "cu_rf_3.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 20s, sys: 1.04 s, total: 22min 21s\n",
      "Wall time: 22min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_3 = cu_rf_3.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7337703108787537\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is almost same as the first experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Random Forest with PCA components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the random forest algorithm with the PCA components and see the results. I will be using the same parameters as I used for the first experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initailise RF object\n",
    "cu_rf_pca = cuRF(**cu_rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the PCA components into the RF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 240 ms, total: 1min 8s\n",
      "Wall time: 19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cu_rf_pca.fit(components, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training took less time as the number of features is less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set will be transformed using the PCA to predict on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.103734</td>\n",
       "      <td>1.478275</td>\n",
       "      <td>-1.150761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.613508</td>\n",
       "      <td>0.668980</td>\n",
       "      <td>-0.019162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.155646</td>\n",
       "      <td>0.298515</td>\n",
       "      <td>-1.125776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.151846</td>\n",
       "      <td>0.549032</td>\n",
       "      <td>0.190880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.414101</td>\n",
       "      <td>-2.323358</td>\n",
       "      <td>1.706555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  2.103734  1.478275 -1.150761\n",
       "1 -0.613508  0.668980 -0.019162\n",
       "2 -0.155646  0.298515 -1.125776\n",
       "3  1.151846  0.549032  0.190880\n",
       "4  1.414101 -2.323358  1.706555"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components_test = pca.transform(X_test_scaled)\n",
    "components_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict method will be run on the test set generated by PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 10s, sys: 176 ms, total: 3min 11s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# using the predict method on test set\n",
    "y_pred_pca = cu_rf_pca.predict(components_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.581381618976593\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy has decreased by using the PCA components. Random Forests works better with more number of dimensions and has the ability to perform better parallel computing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost stands for “Extreme Gradient Boosting”, it is also a powerful supervised machine learning algorithm. In classical machine learning Random Forest and XGBoost are the most powerful algorithms and gives state of the art results which can even be compared to neural networks. XGBoost with RAPIDS can be used for training on GPU. XGBoost can also paralellize well and can train on huge datasets efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert cuDF data to DMatrix format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data loaded is cuDF dataframe. It should be converted to a DMatrix object that XGBoost can work with. We can instantiate an object of the xgboost.DMatrix by passing in the feature matrix as the first argument followed by the label vector using the label= keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.1 ms, sys: 36.5 ms, total: 111 ms\n",
      "Wall time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "dvalidation = xgb.DMatrix(X_test_scaled, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters will be set in the below cell. There is a huge list of parameters that can be tweaked to improve the performance of the model. I will be altering the most important ones that are relevant to our experiment.\n",
    "* silent: It is the verbosity of printing messages. Keeping it at 1 is a standard way and will give us enough information.\n",
    "* tree_method: It is the tree construction algorithm. There are lot of values for it. But the two most important for our purpose are hist and gpu_hist. They perform better on larger datasets, gpu_hist is the gpu implimentation of hist. Since, I am training on GPU, i wil keep it to gpu_hist.\n",
    "* n_gpus: number of gpus to use, change this to -1 to use all GPUs available or 0 to use the CPU\n",
    "* eval_metric: The training method will perform evaluation at the same time. I will be using the area under curve (AUC) score to evaluate the model.\n",
    "* objective: Since ours is the classification problem, I will keep it to binary:logistic to output the classification probablities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'silent': 1, 'tree_method': 'gpu_hist', 'n_gpus': 1, 'eval_metric': 'auc', 'objective': 'binary:logistic'}\n"
     ]
    }
   ],
   "source": [
    "# instantiate params\n",
    "params = {}\n",
    "\n",
    "# general params\n",
    "general_params = {'silent': 1}\n",
    "params.update(general_params)\n",
    "\n",
    "# booster params\n",
    "n_gpus = 1  # change this to -1 to use all GPUs available or 0 to use the CPU\n",
    "booster_params = {}\n",
    "\n",
    "if n_gpus != 0:\n",
    "    booster_params['tree_method'] = 'gpu_hist'\n",
    "    booster_params['n_gpus'] = n_gpus   \n",
    "params.update(booster_params)\n",
    "\n",
    "# learning task params\n",
    "learning_task_params = {}\n",
    "learning_task_params['eval_metric'] = 'auc'\n",
    "learning_task_params['objective'] = 'binary:logistic'\n",
    "    \n",
    "params.update(learning_task_params)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation list is set with train and validation data. The num_round is kept at 100 for 100 steps of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training settings\n",
    "evallist = [(dvalidation, 'validation'), (dtrain, 'train')]\n",
    "num_round = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:45:29] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
      "Parameters: { \"n_gpus\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation-auc:0.74346\ttrain-auc:0.74303\n",
      "[1]\tvalidation-auc:0.75482\ttrain-auc:0.75451\n",
      "[2]\tvalidation-auc:0.76458\ttrain-auc:0.76433\n",
      "[3]\tvalidation-auc:0.77001\ttrain-auc:0.76988\n",
      "[4]\tvalidation-auc:0.77490\ttrain-auc:0.77481\n",
      "[5]\tvalidation-auc:0.78058\ttrain-auc:0.78058\n",
      "[6]\tvalidation-auc:0.78486\ttrain-auc:0.78496\n",
      "[7]\tvalidation-auc:0.78731\ttrain-auc:0.78747\n",
      "[8]\tvalidation-auc:0.78977\ttrain-auc:0.78991\n",
      "[9]\tvalidation-auc:0.79189\ttrain-auc:0.79205\n",
      "[10]\tvalidation-auc:0.79357\ttrain-auc:0.79377\n",
      "[11]\tvalidation-auc:0.79512\ttrain-auc:0.79533\n",
      "[12]\tvalidation-auc:0.79724\ttrain-auc:0.79750\n",
      "[13]\tvalidation-auc:0.79834\ttrain-auc:0.79860\n",
      "[14]\tvalidation-auc:0.79956\ttrain-auc:0.79983\n",
      "[15]\tvalidation-auc:0.80050\ttrain-auc:0.80076\n",
      "[16]\tvalidation-auc:0.80137\ttrain-auc:0.80165\n",
      "[17]\tvalidation-auc:0.80202\ttrain-auc:0.80231\n",
      "[18]\tvalidation-auc:0.80248\ttrain-auc:0.80279\n",
      "[19]\tvalidation-auc:0.80319\ttrain-auc:0.80352\n",
      "[20]\tvalidation-auc:0.80398\ttrain-auc:0.80432\n",
      "[21]\tvalidation-auc:0.80455\ttrain-auc:0.80491\n",
      "[22]\tvalidation-auc:0.80520\ttrain-auc:0.80559\n",
      "[23]\tvalidation-auc:0.80566\ttrain-auc:0.80606\n",
      "[24]\tvalidation-auc:0.80599\ttrain-auc:0.80640\n",
      "[25]\tvalidation-auc:0.80692\ttrain-auc:0.80735\n",
      "[26]\tvalidation-auc:0.80750\ttrain-auc:0.80794\n",
      "[27]\tvalidation-auc:0.80796\ttrain-auc:0.80842\n",
      "[28]\tvalidation-auc:0.80850\ttrain-auc:0.80898\n",
      "[29]\tvalidation-auc:0.80891\ttrain-auc:0.80940\n",
      "[30]\tvalidation-auc:0.80923\ttrain-auc:0.80975\n",
      "[31]\tvalidation-auc:0.80943\ttrain-auc:0.80997\n",
      "[32]\tvalidation-auc:0.80979\ttrain-auc:0.81034\n",
      "[33]\tvalidation-auc:0.81012\ttrain-auc:0.81070\n",
      "[34]\tvalidation-auc:0.81053\ttrain-auc:0.81112\n",
      "[35]\tvalidation-auc:0.81125\ttrain-auc:0.81187\n",
      "[36]\tvalidation-auc:0.81144\ttrain-auc:0.81207\n",
      "[37]\tvalidation-auc:0.81153\ttrain-auc:0.81217\n",
      "[38]\tvalidation-auc:0.81178\ttrain-auc:0.81243\n",
      "[39]\tvalidation-auc:0.81194\ttrain-auc:0.81262\n",
      "[40]\tvalidation-auc:0.81232\ttrain-auc:0.81301\n",
      "[41]\tvalidation-auc:0.81269\ttrain-auc:0.81339\n",
      "[42]\tvalidation-auc:0.81310\ttrain-auc:0.81380\n",
      "[43]\tvalidation-auc:0.81376\ttrain-auc:0.81448\n",
      "[44]\tvalidation-auc:0.81409\ttrain-auc:0.81481\n",
      "[45]\tvalidation-auc:0.81440\ttrain-auc:0.81514\n",
      "[46]\tvalidation-auc:0.81450\ttrain-auc:0.81525\n",
      "[47]\tvalidation-auc:0.81461\ttrain-auc:0.81537\n",
      "[48]\tvalidation-auc:0.81493\ttrain-auc:0.81569\n",
      "[49]\tvalidation-auc:0.81518\ttrain-auc:0.81595\n",
      "[50]\tvalidation-auc:0.81570\ttrain-auc:0.81650\n",
      "[51]\tvalidation-auc:0.81591\ttrain-auc:0.81672\n",
      "[52]\tvalidation-auc:0.81607\ttrain-auc:0.81690\n",
      "[53]\tvalidation-auc:0.81619\ttrain-auc:0.81704\n",
      "[54]\tvalidation-auc:0.81625\ttrain-auc:0.81712\n",
      "[55]\tvalidation-auc:0.81644\ttrain-auc:0.81732\n",
      "[56]\tvalidation-auc:0.81679\ttrain-auc:0.81766\n",
      "[57]\tvalidation-auc:0.81689\ttrain-auc:0.81777\n",
      "[58]\tvalidation-auc:0.81706\ttrain-auc:0.81795\n",
      "[59]\tvalidation-auc:0.81723\ttrain-auc:0.81813\n",
      "[60]\tvalidation-auc:0.81749\ttrain-auc:0.81840\n",
      "[61]\tvalidation-auc:0.81785\ttrain-auc:0.81878\n",
      "[62]\tvalidation-auc:0.81810\ttrain-auc:0.81905\n",
      "[63]\tvalidation-auc:0.81827\ttrain-auc:0.81923\n",
      "[64]\tvalidation-auc:0.81841\ttrain-auc:0.81940\n",
      "[65]\tvalidation-auc:0.81856\ttrain-auc:0.81957\n",
      "[66]\tvalidation-auc:0.81861\ttrain-auc:0.81964\n",
      "[67]\tvalidation-auc:0.81870\ttrain-auc:0.81973\n",
      "[68]\tvalidation-auc:0.81910\ttrain-auc:0.82012\n",
      "[69]\tvalidation-auc:0.81929\ttrain-auc:0.82031\n",
      "[70]\tvalidation-auc:0.81942\ttrain-auc:0.82045\n",
      "[71]\tvalidation-auc:0.81960\ttrain-auc:0.82065\n",
      "[72]\tvalidation-auc:0.81964\ttrain-auc:0.82070\n",
      "[73]\tvalidation-auc:0.81975\ttrain-auc:0.82082\n",
      "[74]\tvalidation-auc:0.81991\ttrain-auc:0.82100\n",
      "[75]\tvalidation-auc:0.82025\ttrain-auc:0.82135\n",
      "[76]\tvalidation-auc:0.82033\ttrain-auc:0.82144\n",
      "[77]\tvalidation-auc:0.82055\ttrain-auc:0.82168\n",
      "[78]\tvalidation-auc:0.82069\ttrain-auc:0.82184\n",
      "[79]\tvalidation-auc:0.82088\ttrain-auc:0.82203\n",
      "[80]\tvalidation-auc:0.82093\ttrain-auc:0.82210\n",
      "[81]\tvalidation-auc:0.82108\ttrain-auc:0.82226\n",
      "[82]\tvalidation-auc:0.82127\ttrain-auc:0.82245\n",
      "[83]\tvalidation-auc:0.82132\ttrain-auc:0.82252\n",
      "[84]\tvalidation-auc:0.82138\ttrain-auc:0.82258\n",
      "[85]\tvalidation-auc:0.82148\ttrain-auc:0.82269\n",
      "[86]\tvalidation-auc:0.82153\ttrain-auc:0.82276\n",
      "[87]\tvalidation-auc:0.82173\ttrain-auc:0.82297\n",
      "[88]\tvalidation-auc:0.82185\ttrain-auc:0.82310\n",
      "[89]\tvalidation-auc:0.82187\ttrain-auc:0.82313\n",
      "[90]\tvalidation-auc:0.82198\ttrain-auc:0.82326\n",
      "[91]\tvalidation-auc:0.82207\ttrain-auc:0.82335\n",
      "[92]\tvalidation-auc:0.82237\ttrain-auc:0.82368\n",
      "[93]\tvalidation-auc:0.82249\ttrain-auc:0.82381\n",
      "[94]\tvalidation-auc:0.82269\ttrain-auc:0.82402\n",
      "[95]\tvalidation-auc:0.82285\ttrain-auc:0.82420\n",
      "[96]\tvalidation-auc:0.82305\ttrain-auc:0.82440\n",
      "[97]\tvalidation-auc:0.82325\ttrain-auc:0.82461\n",
      "[98]\tvalidation-auc:0.82331\ttrain-auc:0.82469\n",
      "[99]\tvalidation-auc:0.82334\ttrain-auc:0.82473\n",
      "CPU times: user 3.27 s, sys: 86.9 ms, total: 3.36 s\n",
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_pred = bst.predict(dvalidation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the predictions made by XGBoost are probabilities. To get the accuracy score, I will convert them to binary class values by rounding them to 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_predictions = [round(value) for value in bst_pred]\n",
    "bst_predictions = np.array(bst_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an improvement of 1% in accuracy. XGBoost has performed better than Random Forest on this data with these set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.742078959941864\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, bst_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is that XGBoost does not give option to evaluate on accuracy score, it gives option of ROC AUC score for classification problems. The difference between them is that accuracy score calculates accuracy on the predicted classes while ROC AUC calculates on the predicted scores. ROC AUC is a better classification metric for complex problems. Let's check the ROC AUC score of the model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score:  0.8233452439308167\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC score: ', roc_auc_score(y_test, bst_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives a good result. I will discuss more about the results in the evaluation notebook. Let's optimize the hyperparameters and perform another experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the parameters are same with some additional changes. \n",
    "* max_depth: Default value is 6, I will change it to 7. Increasing this value will result in overfitting, that is why I will increase it to just 7.\n",
    "* reg_lambda: Increasing this value makes the model more conservative. I will update it to 2.\n",
    "* scale_pos_weight: This is useful for unblanced classes. It controls the balance between negative and positive weights. Default is 1, I will update it to 2.\n",
    "* gamma: Default is 0. Larger values will make the model more conservative. I will update it to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_2 = {\n",
    "    'silent': 1, 'tree_method': 'gpu_hist', 'n_gpus': 1, 'eval_metric': 'auc', \n",
    "    'objective': 'binary:logistic', 'max_depth': 7, 'reg_lambda': 2, 'scale_pos_weight': 2, \n",
    "    'gamma': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:16] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
      "Parameters: { \"n_gpus\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation-auc:0.75312\ttrain-auc:0.75312\n",
      "[1]\tvalidation-auc:0.75983\ttrain-auc:0.75979\n",
      "[2]\tvalidation-auc:0.76449\ttrain-auc:0.76444\n",
      "[3]\tvalidation-auc:0.76761\ttrain-auc:0.76758\n",
      "[4]\tvalidation-auc:0.77079\ttrain-auc:0.77077\n",
      "[5]\tvalidation-auc:0.77253\ttrain-auc:0.77252\n",
      "[6]\tvalidation-auc:0.77430\ttrain-auc:0.77431\n",
      "[7]\tvalidation-auc:0.77615\ttrain-auc:0.77620\n",
      "[8]\tvalidation-auc:0.77786\ttrain-auc:0.77790\n",
      "[9]\tvalidation-auc:0.77969\ttrain-auc:0.77975\n",
      "[10]\tvalidation-auc:0.78109\ttrain-auc:0.78117\n",
      "[11]\tvalidation-auc:0.78244\ttrain-auc:0.78252\n",
      "[12]\tvalidation-auc:0.78397\ttrain-auc:0.78405\n",
      "[13]\tvalidation-auc:0.78502\ttrain-auc:0.78513\n",
      "[14]\tvalidation-auc:0.78667\ttrain-auc:0.78677\n",
      "[15]\tvalidation-auc:0.78755\ttrain-auc:0.78769\n",
      "[16]\tvalidation-auc:0.78883\ttrain-auc:0.78900\n",
      "[17]\tvalidation-auc:0.79021\ttrain-auc:0.79040\n",
      "[18]\tvalidation-auc:0.79160\ttrain-auc:0.79181\n",
      "[19]\tvalidation-auc:0.79279\ttrain-auc:0.79300\n",
      "[20]\tvalidation-auc:0.79360\ttrain-auc:0.79385\n",
      "[21]\tvalidation-auc:0.79478\ttrain-auc:0.79504\n",
      "[22]\tvalidation-auc:0.79585\ttrain-auc:0.79615\n",
      "[23]\tvalidation-auc:0.79672\ttrain-auc:0.79703\n",
      "[24]\tvalidation-auc:0.79773\ttrain-auc:0.79806\n",
      "[25]\tvalidation-auc:0.79854\ttrain-auc:0.79889\n",
      "[26]\tvalidation-auc:0.79932\ttrain-auc:0.79970\n",
      "[27]\tvalidation-auc:0.80008\ttrain-auc:0.80047\n",
      "[28]\tvalidation-auc:0.80081\ttrain-auc:0.80122\n",
      "[29]\tvalidation-auc:0.80137\ttrain-auc:0.80177\n",
      "[30]\tvalidation-auc:0.80203\ttrain-auc:0.80245\n",
      "[31]\tvalidation-auc:0.80262\ttrain-auc:0.80306\n",
      "[32]\tvalidation-auc:0.80309\ttrain-auc:0.80355\n",
      "[33]\tvalidation-auc:0.80362\ttrain-auc:0.80409\n",
      "[34]\tvalidation-auc:0.80404\ttrain-auc:0.80454\n",
      "[35]\tvalidation-auc:0.80447\ttrain-auc:0.80497\n",
      "[36]\tvalidation-auc:0.80491\ttrain-auc:0.80542\n",
      "[37]\tvalidation-auc:0.80522\ttrain-auc:0.80574\n",
      "[38]\tvalidation-auc:0.80577\ttrain-auc:0.80630\n",
      "[39]\tvalidation-auc:0.80611\ttrain-auc:0.80665\n",
      "[40]\tvalidation-auc:0.80651\ttrain-auc:0.80707\n",
      "[41]\tvalidation-auc:0.80695\ttrain-auc:0.80751\n",
      "[42]\tvalidation-auc:0.80729\ttrain-auc:0.80785\n",
      "[43]\tvalidation-auc:0.80759\ttrain-auc:0.80816\n",
      "[44]\tvalidation-auc:0.80780\ttrain-auc:0.80838\n",
      "[45]\tvalidation-auc:0.80806\ttrain-auc:0.80864\n",
      "[46]\tvalidation-auc:0.80853\ttrain-auc:0.80912\n",
      "[47]\tvalidation-auc:0.80888\ttrain-auc:0.80949\n",
      "[48]\tvalidation-auc:0.80914\ttrain-auc:0.80976\n",
      "[49]\tvalidation-auc:0.80936\ttrain-auc:0.80999\n",
      "[50]\tvalidation-auc:0.80956\ttrain-auc:0.81021\n",
      "[51]\tvalidation-auc:0.80976\ttrain-auc:0.81041\n",
      "[52]\tvalidation-auc:0.81003\ttrain-auc:0.81069\n",
      "[53]\tvalidation-auc:0.81026\ttrain-auc:0.81093\n",
      "[54]\tvalidation-auc:0.81046\ttrain-auc:0.81114\n",
      "[55]\tvalidation-auc:0.81063\ttrain-auc:0.81131\n",
      "[56]\tvalidation-auc:0.81094\ttrain-auc:0.81161\n",
      "[57]\tvalidation-auc:0.81114\ttrain-auc:0.81182\n",
      "[58]\tvalidation-auc:0.81135\ttrain-auc:0.81204\n",
      "[59]\tvalidation-auc:0.81156\ttrain-auc:0.81225\n",
      "[60]\tvalidation-auc:0.81168\ttrain-auc:0.81238\n",
      "[61]\tvalidation-auc:0.81180\ttrain-auc:0.81251\n",
      "[62]\tvalidation-auc:0.81199\ttrain-auc:0.81270\n",
      "[63]\tvalidation-auc:0.81217\ttrain-auc:0.81290\n",
      "[64]\tvalidation-auc:0.81239\ttrain-auc:0.81312\n",
      "[65]\tvalidation-auc:0.81265\ttrain-auc:0.81338\n",
      "[66]\tvalidation-auc:0.81283\ttrain-auc:0.81357\n",
      "[67]\tvalidation-auc:0.81310\ttrain-auc:0.81385\n",
      "[68]\tvalidation-auc:0.81320\ttrain-auc:0.81396\n",
      "[69]\tvalidation-auc:0.81331\ttrain-auc:0.81408\n",
      "[70]\tvalidation-auc:0.81351\ttrain-auc:0.81429\n",
      "[71]\tvalidation-auc:0.81376\ttrain-auc:0.81456\n",
      "[72]\tvalidation-auc:0.81399\ttrain-auc:0.81478\n",
      "[73]\tvalidation-auc:0.81413\ttrain-auc:0.81494\n",
      "[74]\tvalidation-auc:0.81428\ttrain-auc:0.81510\n",
      "[75]\tvalidation-auc:0.81440\ttrain-auc:0.81523\n",
      "[76]\tvalidation-auc:0.81459\ttrain-auc:0.81543\n",
      "[77]\tvalidation-auc:0.81469\ttrain-auc:0.81554\n",
      "[78]\tvalidation-auc:0.81486\ttrain-auc:0.81572\n",
      "[79]\tvalidation-auc:0.81505\ttrain-auc:0.81590\n",
      "[80]\tvalidation-auc:0.81521\ttrain-auc:0.81608\n",
      "[81]\tvalidation-auc:0.81534\ttrain-auc:0.81622\n",
      "[82]\tvalidation-auc:0.81544\ttrain-auc:0.81633\n",
      "[83]\tvalidation-auc:0.81549\ttrain-auc:0.81639\n",
      "[84]\tvalidation-auc:0.81563\ttrain-auc:0.81653\n",
      "[85]\tvalidation-auc:0.81581\ttrain-auc:0.81673\n",
      "[86]\tvalidation-auc:0.81597\ttrain-auc:0.81690\n",
      "[87]\tvalidation-auc:0.81614\ttrain-auc:0.81708\n",
      "[88]\tvalidation-auc:0.81631\ttrain-auc:0.81726\n",
      "[89]\tvalidation-auc:0.81657\ttrain-auc:0.81753\n",
      "[90]\tvalidation-auc:0.81674\ttrain-auc:0.81770\n",
      "[91]\tvalidation-auc:0.81687\ttrain-auc:0.81785\n",
      "[92]\tvalidation-auc:0.81697\ttrain-auc:0.81796\n",
      "[93]\tvalidation-auc:0.81713\ttrain-auc:0.81813\n",
      "[94]\tvalidation-auc:0.81747\ttrain-auc:0.81848\n",
      "[95]\tvalidation-auc:0.81753\ttrain-auc:0.81854\n",
      "[96]\tvalidation-auc:0.81769\ttrain-auc:0.81871\n",
      "[97]\tvalidation-auc:0.81775\ttrain-auc:0.81877\n",
      "[98]\tvalidation-auc:0.81786\ttrain-auc:0.81889\n",
      "[99]\tvalidation-auc:0.81800\ttrain-auc:0.81903\n",
      "CPU times: user 4.04 s, sys: 66 ms, total: 4.1 s\n",
      "Wall time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bst_2 = xgb.train(params_2, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_pred_2 = bst_2.predict(dvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_predictions_2 = [round(value) for value in bst_pred_2]\n",
    "bst_predictions_2 = np.array(bst_predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7026330232620239\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, bst_predictions_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score:  0.8179947137832642\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC score: ', roc_auc_score(y_test, bst_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy and ROC AUC scores have reduced with the optimisations. It is a complex dataset and more feature engineering is required to improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with PCA componenets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will use the PCA components with XGBoost and check the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_pca = xgb.DMatrix(components, label=y_train)\n",
    "dvalidation_pca = xgb.DMatrix(components_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training settings\n",
    "evallist_pca = [(dvalidation_pca, 'validation'), (dtrain_pca, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:08:44] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
      "Parameters: { \"n_gpus\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation-auc:0.59165\ttrain-auc:0.59142\n",
      "[1]\tvalidation-auc:0.59369\ttrain-auc:0.59349\n",
      "[2]\tvalidation-auc:0.59533\ttrain-auc:0.59512\n",
      "[3]\tvalidation-auc:0.59667\ttrain-auc:0.59643\n",
      "[4]\tvalidation-auc:0.59732\ttrain-auc:0.59708\n",
      "[5]\tvalidation-auc:0.59753\ttrain-auc:0.59732\n",
      "[6]\tvalidation-auc:0.59781\ttrain-auc:0.59764\n",
      "[7]\tvalidation-auc:0.59807\ttrain-auc:0.59801\n",
      "[8]\tvalidation-auc:0.59817\ttrain-auc:0.59813\n",
      "[9]\tvalidation-auc:0.59844\ttrain-auc:0.59843\n",
      "[10]\tvalidation-auc:0.59852\ttrain-auc:0.59852\n",
      "[11]\tvalidation-auc:0.59855\ttrain-auc:0.59857\n",
      "[12]\tvalidation-auc:0.59861\ttrain-auc:0.59866\n",
      "[13]\tvalidation-auc:0.59868\ttrain-auc:0.59875\n",
      "[14]\tvalidation-auc:0.59872\ttrain-auc:0.59881\n",
      "[15]\tvalidation-auc:0.59876\ttrain-auc:0.59886\n",
      "[16]\tvalidation-auc:0.59881\ttrain-auc:0.59895\n",
      "[17]\tvalidation-auc:0.59882\ttrain-auc:0.59898\n",
      "[18]\tvalidation-auc:0.59884\ttrain-auc:0.59902\n",
      "[19]\tvalidation-auc:0.59884\ttrain-auc:0.59904\n",
      "[20]\tvalidation-auc:0.59884\ttrain-auc:0.59906\n",
      "[21]\tvalidation-auc:0.59889\ttrain-auc:0.59913\n",
      "[22]\tvalidation-auc:0.59888\ttrain-auc:0.59917\n",
      "[23]\tvalidation-auc:0.59889\ttrain-auc:0.59920\n",
      "[24]\tvalidation-auc:0.59889\ttrain-auc:0.59922\n",
      "[25]\tvalidation-auc:0.59891\ttrain-auc:0.59927\n",
      "[26]\tvalidation-auc:0.59891\ttrain-auc:0.59931\n",
      "[27]\tvalidation-auc:0.59891\ttrain-auc:0.59933\n",
      "[28]\tvalidation-auc:0.59891\ttrain-auc:0.59934\n",
      "[29]\tvalidation-auc:0.59891\ttrain-auc:0.59937\n",
      "[30]\tvalidation-auc:0.59891\ttrain-auc:0.59939\n",
      "[31]\tvalidation-auc:0.59891\ttrain-auc:0.59942\n",
      "[32]\tvalidation-auc:0.59891\ttrain-auc:0.59945\n",
      "[33]\tvalidation-auc:0.59891\ttrain-auc:0.59945\n",
      "[34]\tvalidation-auc:0.59891\ttrain-auc:0.59947\n",
      "[35]\tvalidation-auc:0.59892\ttrain-auc:0.59950\n",
      "[36]\tvalidation-auc:0.59891\ttrain-auc:0.59952\n",
      "[37]\tvalidation-auc:0.59891\ttrain-auc:0.59955\n",
      "[38]\tvalidation-auc:0.59890\ttrain-auc:0.59957\n",
      "[39]\tvalidation-auc:0.59890\ttrain-auc:0.59958\n",
      "[40]\tvalidation-auc:0.59890\ttrain-auc:0.59961\n",
      "[41]\tvalidation-auc:0.59890\ttrain-auc:0.59964\n",
      "[42]\tvalidation-auc:0.59890\ttrain-auc:0.59966\n",
      "[43]\tvalidation-auc:0.59889\ttrain-auc:0.59968\n",
      "[44]\tvalidation-auc:0.59889\ttrain-auc:0.59971\n",
      "[45]\tvalidation-auc:0.59889\ttrain-auc:0.59974\n",
      "[46]\tvalidation-auc:0.59889\ttrain-auc:0.59975\n",
      "[47]\tvalidation-auc:0.59889\ttrain-auc:0.59978\n",
      "[48]\tvalidation-auc:0.59888\ttrain-auc:0.59980\n",
      "[49]\tvalidation-auc:0.59888\ttrain-auc:0.59982\n",
      "[50]\tvalidation-auc:0.59888\ttrain-auc:0.59984\n",
      "[51]\tvalidation-auc:0.59887\ttrain-auc:0.59986\n",
      "[52]\tvalidation-auc:0.59887\ttrain-auc:0.59987\n",
      "[53]\tvalidation-auc:0.59887\ttrain-auc:0.59990\n",
      "[54]\tvalidation-auc:0.59887\ttrain-auc:0.59991\n",
      "[55]\tvalidation-auc:0.59887\ttrain-auc:0.59993\n",
      "[56]\tvalidation-auc:0.59887\ttrain-auc:0.59995\n",
      "[57]\tvalidation-auc:0.59887\ttrain-auc:0.59997\n",
      "[58]\tvalidation-auc:0.59887\ttrain-auc:0.59999\n",
      "[59]\tvalidation-auc:0.59887\ttrain-auc:0.60001\n",
      "[60]\tvalidation-auc:0.59887\ttrain-auc:0.60003\n",
      "[61]\tvalidation-auc:0.59887\ttrain-auc:0.60005\n",
      "[62]\tvalidation-auc:0.59887\ttrain-auc:0.60005\n",
      "[63]\tvalidation-auc:0.59886\ttrain-auc:0.60007\n",
      "[64]\tvalidation-auc:0.59886\ttrain-auc:0.60009\n",
      "[65]\tvalidation-auc:0.59886\ttrain-auc:0.60010\n",
      "[66]\tvalidation-auc:0.59885\ttrain-auc:0.60011\n",
      "[67]\tvalidation-auc:0.59885\ttrain-auc:0.60015\n",
      "[68]\tvalidation-auc:0.59884\ttrain-auc:0.60016\n",
      "[69]\tvalidation-auc:0.59883\ttrain-auc:0.60018\n",
      "[70]\tvalidation-auc:0.59883\ttrain-auc:0.60021\n",
      "[71]\tvalidation-auc:0.59883\ttrain-auc:0.60023\n",
      "[72]\tvalidation-auc:0.59883\ttrain-auc:0.60024\n",
      "[73]\tvalidation-auc:0.59883\ttrain-auc:0.60025\n",
      "[74]\tvalidation-auc:0.59882\ttrain-auc:0.60026\n",
      "[75]\tvalidation-auc:0.59882\ttrain-auc:0.60026\n",
      "[76]\tvalidation-auc:0.59882\ttrain-auc:0.60029\n",
      "[77]\tvalidation-auc:0.59882\ttrain-auc:0.60031\n",
      "[78]\tvalidation-auc:0.59881\ttrain-auc:0.60033\n",
      "[79]\tvalidation-auc:0.59880\ttrain-auc:0.60035\n",
      "[80]\tvalidation-auc:0.59880\ttrain-auc:0.60038\n",
      "[81]\tvalidation-auc:0.59879\ttrain-auc:0.60040\n",
      "[82]\tvalidation-auc:0.59879\ttrain-auc:0.60041\n",
      "[83]\tvalidation-auc:0.59879\ttrain-auc:0.60043\n",
      "[84]\tvalidation-auc:0.59879\ttrain-auc:0.60045\n",
      "[85]\tvalidation-auc:0.59879\ttrain-auc:0.60047\n",
      "[86]\tvalidation-auc:0.59879\ttrain-auc:0.60049\n",
      "[87]\tvalidation-auc:0.59878\ttrain-auc:0.60051\n",
      "[88]\tvalidation-auc:0.59878\ttrain-auc:0.60052\n",
      "[89]\tvalidation-auc:0.59878\ttrain-auc:0.60053\n",
      "[90]\tvalidation-auc:0.59878\ttrain-auc:0.60054\n",
      "[91]\tvalidation-auc:0.59877\ttrain-auc:0.60057\n",
      "[92]\tvalidation-auc:0.59877\ttrain-auc:0.60059\n",
      "[93]\tvalidation-auc:0.59877\ttrain-auc:0.60060\n",
      "[94]\tvalidation-auc:0.59877\ttrain-auc:0.60063\n",
      "[95]\tvalidation-auc:0.59876\ttrain-auc:0.60065\n",
      "[96]\tvalidation-auc:0.59876\ttrain-auc:0.60067\n",
      "[97]\tvalidation-auc:0.59875\ttrain-auc:0.60069\n",
      "[98]\tvalidation-auc:0.59875\ttrain-auc:0.60071\n",
      "[99]\tvalidation-auc:0.59875\ttrain-auc:0.60073\n",
      "CPU times: user 1.74 s, sys: 84.4 ms, total: 1.82 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bst_pca = xgb.train(params, dtrain_pca, num_round, evallist_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_pred_pca = bst_pca.predict(dvalidation_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score:  0.5987499952316284\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC score: ', roc_auc_score(y_test, bst_pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost with PCA components did not perform good. Both XGBoost and Random Forests behaves in a same way and performs better with high dimensions of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13eb2e2d374e1989b1aee4411b7d54fcf0488dac9d6327102b0d70b3bff01564"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
